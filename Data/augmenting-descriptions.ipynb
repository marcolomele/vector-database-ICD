{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv('icd11_data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'code', 'title', 'browser_url', 'class_kind', 'definition',\n",
       "       'parent', 'inclusions', 'foundation_children',\n",
       "       'foundation_child_references', 'index_terms', 'related_entities',\n",
       "       'full_text', 'children', 'postcoordination_scales',\n",
       "       'index_term_references', 'exclusions', 'exclusion_references',\n",
       "       'fully_specified_name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Define the system message\n",
    "SYSTEM_MESSAGE = \"\"\"\n",
    "Your name is Llama3-OpenBioLLM-70B. You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge.\n",
    "Your mission is to provide comprehensive, technical, and accurate medical description descriptions of diseases and disease categories.\n",
    "The user will input the name of a diseases or the name of a category of diseases.\n",
    "You will provide the description of the query. \n",
    "Always structure the sentences of your response in this order: overview, causes, symptoms, transmission, diagnosis. \n",
    "Write full sentences, using a concise and clear language.\n",
    "\"\"\"\n",
    "\n",
    "def get_medical_definition(query, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Get a medical definition using the Nebius API and Llama3-OpenBioLLM-70B model.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The medical condition or term to define\n",
    "        temperature (float, optional): Controls randomness in the response. \n",
    "                                     Lower values make the output more focused and deterministic.\n",
    "                                     Defaults to 0.1.\n",
    "    \n",
    "    Returns:\n",
    "        str: The model's response containing the medical definition\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the API key is not found in environment variables\n",
    "    \"\"\"\n",
    "    # Check if API key exists\n",
    "    api_key = os.getenv('NEBIUS_API_KEY')\n",
    "    if not api_key:\n",
    "        raise ValueError(\"NEBIUS_API_KEY not found in environment variables\")\n",
    "    \n",
    "    # Initialize the client\n",
    "    client_nebius = OpenAI(\n",
    "        base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "        api_key=api_key)\n",
    "    \n",
    "    try:\n",
    "        response = client_nebius.chat.completions.create(\n",
    "            model=\"aaditya/Llama3-OpenBioLLM-70B\",\n",
    "            temperature=temperature,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "                {\"role\": \"user\", \"content\": f\"Describe {query}?\"}\n",
    "            ],\n",
    "            max_completion_tokens=800 # set by looking at the length of the 3rd longest definition, first and second longest need cleaning\n",
    "        )\n",
    "        \n",
    "        # Return the response text\n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting medical definition: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions: 100%|██████████| 13373/13373 [2:58:04<00:00,  1.25it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "\n",
    "# Create a new column for generated descriptions\n",
    "d['generated_description'] = None\n",
    "\n",
    "def process_row(row_data):\n",
    "    \"\"\"\n",
    "    Process a single row and return the result\n",
    "    \"\"\"\n",
    "    idx, row = row_data\n",
    "    try:\n",
    "        disease_title = row['title']\n",
    "        generated_desc = get_medical_definition(disease_title)\n",
    "        return idx, generated_desc\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError processing row {idx} for disease {disease_title}: {str(e)}\")\n",
    "        return idx, None\n",
    "\n",
    "# Number of threads to use\n",
    "num_threads = 8\n",
    "\n",
    "# Create a progress bar\n",
    "pbar = tqdm(total=13373, desc=\"Generating descriptions\")\n",
    "\n",
    "# Process rows in parallel using threads\n",
    "with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    # Submit all rows for processing\n",
    "    future_to_row = {\n",
    "        executor.submit(process_row, (idx, row)): idx \n",
    "        for idx, row in d.iloc[:13373].iterrows()\n",
    "    }\n",
    "    \n",
    "    # Process results as they complete\n",
    "    for future in as_completed(future_to_row):\n",
    "        idx, desc = future.result()\n",
    "        d.at[idx, 'generated_description'] = desc\n",
    "        pbar.update(1)\n",
    "        \n",
    "        # Save progress every 100 rows\n",
    "        if idx % 100 == 0:\n",
    "            d.to_csv('icd11_data_with_generated_descriptions.csv', index=False)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Final save\n",
    "d.to_csv('icd11_data_with_generated_descriptions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def generate_descriptions_for_dataframe(df, num_threads=8, batch_size=100):\n",
    "    \"\"\"\n",
    "    Add generated descriptions for disease titles to a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: A pandas DataFrame containing at least a 'title' column\n",
    "        num_threads: Number of parallel threads to use (default: 8)\n",
    "        batch_size: How often to save intermediate results (default: 100)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added 'generated_description' column\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy of the dataframe to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Add the new column\n",
    "    result_df['generated_description'] = None\n",
    "    \n",
    "    def process_row(row_data):\n",
    "        \"\"\"Process a single row and return the result\"\"\"\n",
    "        idx, row = row_data\n",
    "        try:\n",
    "            disease_title = row['title']\n",
    "            generated_desc = get_medical_definition(disease_title)\n",
    "            return idx, generated_desc\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError processing row {idx} for disease {row['title']}: {str(e)}\")\n",
    "            return idx, None\n",
    "    \n",
    "    # Create a progress bar\n",
    "    total_rows = len(result_df)\n",
    "    pbar = tqdm(total=total_rows, desc=\"Generating descriptions\")\n",
    "    \n",
    "    # Process rows in parallel using threads\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        # Submit all rows for processing\n",
    "        future_to_row = {\n",
    "            executor.submit(process_row, (idx, row)): idx \n",
    "            for idx, row in result_df.iterrows()\n",
    "        }\n",
    "        \n",
    "        temp_file_path = 'temp_descriptions_progress.csv'\n",
    "        \n",
    "        # Process results as they complete\n",
    "        for future in as_completed(future_to_row):\n",
    "            idx, desc = future.result()\n",
    "            result_df.at[idx, 'generated_description'] = desc\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Save progress at regular intervals\n",
    "            if idx % batch_size == 0:\n",
    "                result_df.to_csv(temp_file_path, index=False)\n",
    "    \n",
    "    pbar.close()\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging on ICD 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13373, 20)\n",
      "(13960, 19)\n"
     ]
    }
   ],
   "source": [
    "df23 = pd.read_csv('icd11-23_data_with_generated_descriptions.csv').iloc[:13373] ; print(df23.shape)\n",
    "df25 = pd.read_csv('icd11-25_data_raw.csv') ; print(df25.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df23_ids_gen = df23[['id', 'generated_description']].copy()\n",
    "df25 = df25.merge(df23_ids_gen, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = df25[df25['generated_description'].isna()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions:   0%|          | 0/618 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating descriptions: 100%|██████████| 618/618 [08:25<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "df25_sub = df25.iloc[target_ids][['id', 'title']].copy()\n",
    "df25_sub = generate_descriptions_for_dataframe(df25_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>browser_url</th>\n",
       "      <th>class_kind</th>\n",
       "      <th>definition</th>\n",
       "      <th>parent</th>\n",
       "      <th>inclusions</th>\n",
       "      <th>foundation_children</th>\n",
       "      <th>foundation_child_references</th>\n",
       "      <th>index_terms</th>\n",
       "      <th>related_entities</th>\n",
       "      <th>full_text</th>\n",
       "      <th>children</th>\n",
       "      <th>postcoordination_scales</th>\n",
       "      <th>index_term_references</th>\n",
       "      <th>exclusions</th>\n",
       "      <th>exclusion_references</th>\n",
       "      <th>fully_specified_name</th>\n",
       "      <th>generated_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, code, title, browser_url, class_kind, definition, parent, inclusions, foundation_children, foundation_child_references, index_terms, related_entities, full_text, children, postcoordination_scales, index_term_references, exclusions, exclusion_references, fully_specified_name, generated_description]\n",
       "Index: []"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df25.loc[target_ids, 'generated_description'] = df25_sub['generated_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df25.to_csv('icd11-25_data_with_generated_descriptions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_icd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
