{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b03efb",
   "metadata": {
    "id": "11b03efb"
   },
   "source": [
    "# ICD-11 BERT Embeddings Generator - Google Colab Notebook\n",
    " This notebook generates embeddings for ICD-11 codes using various BERT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10497e9d",
   "metadata": {
    "id": "10497e9d",
    "outputId": "dd2983b5-cd1c-45c8-a639-dbe1924d08f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Desktop\\2_NLP\\_Project_\\vector-database-ICD\\vector-database-ICD\\.conda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c73a0c",
   "metadata": {
    "id": "a2c73a0c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def bert_embeddings(file_in, file_out, model_name='bert-base-uncased', batch_size=16, max_length=512, device=None):\n",
    "    df = pd.read_csv(file_in)\n",
    "    texts = df['vectorization_text'].fillna('').astype(str).tolist()\n",
    "    codes = df['code'].tolist()\n",
    "\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_embeddings = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=f\"{model_name} embeddings\"):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        encoded = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded)\n",
    "            token_embeddings = outputs.last_hidden_state\n",
    "            attention_mask = encoded['attention_mask']\n",
    "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "            sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "            embeddings = (sum_embeddings / sum_mask).cpu().numpy()\n",
    "        all_embeddings.extend(embeddings)\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        shape=all_embeddings[0].shape\n",
    "    df_embeddings = pd.DataFrame({\n",
    "        \"ICD11_code\": codes,\n",
    "        \"Vector\": [np.array2string(vec, separator=',', precision=6, suppress_small=True) for vec in all_embeddings]\n",
    "    })\n",
    "\n",
    "    print(f\"Number of rows in resulting DataFrame: {len(df_embeddings)}\")\n",
    "    print(f\"Shape of the first vector: {shape}\")\n",
    "\n",
    "    df_embeddings.to_csv(file_out, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399cafa",
   "metadata": {
    "id": "8399cafa"
   },
   "outputs": [],
   "source": [
    "# --- LOOP OVER ALL MODELS ---\n",
    "MODELS = {\n",
    "    'bert': 'bert-base-uncased',\n",
    "    'biobert': 'dmis-lab/biobert-base-cased-v1.1',\n",
    "    'bioclinicalbert': 'emilyalsentzer/Bio_ClinicalBERT',\n",
    "    'pubmedbert': 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b381c",
   "metadata": {
    "id": "739b381c"
   },
   "outputs": [],
   "source": [
    "# embeddings for ICD11 codes\n",
    "for model_name, model_path in MODELS.items():\n",
    "    out_file = f\"{model_name}_ICD11_embeddings.csv\"\n",
    "    print(f\"\\nProcessing {model_name}...\")\n",
    "    bert_embeddings(\"ICD11_preprocessed.csv\", out_file, model_name=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db7a623",
   "metadata": {
    "collapsed": true,
    "id": "1db7a623",
    "outputId": "b5f771fd-2ed8-4447-9f34-23c50de90aa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert-base-uncased embeddings: 100%|██████████| 24/24 [00:35<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 378\n",
      "Shape of the first vector: (768,)\n",
      "\n",
      "Processing biobert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmis-lab/biobert-base-cased-v1.1 embeddings: 100%|██████████| 24/24 [00:40<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 378\n",
      "Shape of the first vector: (768,)\n",
      "\n",
      "Processing bioclinicalbert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emilyalsentzer/Bio_ClinicalBERT embeddings: 100%|██████████| 24/24 [00:34<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 378\n",
      "Shape of the first vector: (768,)\n",
      "\n",
      "Processing pubmedbert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext embeddings: 100%|██████████| 24/24 [00:34<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 378\n",
      "Shape of the first vector: (768,)\n"
     ]
    }
   ],
   "source": [
    "# embeddings for Merriam-Webster definitions\n",
    "for model_name, model_path in MODELS.items():\n",
    "    out_file = f\"{model_name}_encyclopedia_embeddings.csv\"\n",
    "    print(f\"\\nProcessing {model_name}...\")\n",
    "    bert_embeddings(\"definitions2vec/encyclopedia_sd_preprocessed.csv\", out_file, model_name=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e4491",
   "metadata": {
    "id": "8b5e4491",
    "outputId": "468acec0-08ee-407b-b49d-8bdbf61a6d36",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing bert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bert-base-uncased embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 10\n",
      "Shape of the first vector: (768,)\n",
      "\n",
      "Processing biobert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dmis-lab/biobert-base-cased-v1.1 embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 10\n",
      "Shape of the first vector: (768,)\n",
      "\n",
      "Processing bioclinicalbert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emilyalsentzer/Bio_ClinicalBERT embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 10\n",
      "Shape of the first vector: (768,)\n",
      "\n",
      "Processing pubmedbert...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in resulting DataFrame: 10\n",
      "Shape of the first vector: (768,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# embeddings for Non-medical prompts\n",
    "for model_name, model_path in MODELS.items():\n",
    "    out_file = f\"{model_name}_non_medical_prompts_embeddings.csv\"\n",
    "    print(f\"\\nProcessing {model_name}...\")\n",
    "    bert_embeddings(\"Non_medical_prompts_preprocessed.csv\", out_file, model_name=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef85f0",
   "metadata": {
    "id": "37ef85f0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
